{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVrM5DWE0KmD1tkHO8ui7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calisley/dpi-681/blob/main/section_4/Section_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRU0Rn0SgQZg",
        "outputId": "d17dd4aa-df06-4874-adc3-d3de8fb67368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY is set in Colab Secrets.\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from google.colab import userdata\n",
        "from google.colab.userdata import SecretNotFoundError\n",
        "from getpass import getpass\n",
        "\n",
        "try:\n",
        "    key = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"OPENAI_API_KEY is set in Colab Secrets.\")\n",
        "except SecretNotFoundError:\n",
        "    print(\"No OPENAI_API_KEY found in Colab Secrets.\")\n",
        "    print(\"Open the 'Secrets' tab on the left (the key icon')\")\n",
        "    print(\"Click 'Add new secret'\")\n",
        "    print(\"Set the name to OPENAI_API_KEY\")\n",
        "    print(\"Set the value to your API key\")\n",
        "    print(\"Click on the 'notebook access' toggle to turn it on\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os, json, requests\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY missing from Colab Secrets. Rerun the secrets cell.\")\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "H5GmcNgtgnik"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0: Square Function and Tool Use"
      ],
      "metadata": {
        "id": "XR8dVXbmnXlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square(number):\n",
        "    return number ** 2"
      ],
      "metadata": {
        "id": "8vcDLDtxjGZU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [{\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"square\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"number\": { \"type\": \"number\" }\n",
        "        },\n",
        "        \"required\": [\"number\"]\n",
        "    }\n",
        "}]"
      ],
      "metadata": {
        "id": "_wxuS4wYgX6k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.responses.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        input=\"What is 17^2? use any tools you have available\",\n",
        "        tools=tools\n",
        "  )"
      ],
      "metadata": {
        "id": "OBxAP2A5gW2S"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in resp.output:\n",
        "    if item.type == \"function_call\" and item.name == \"square\":\n",
        "        args = json.loads(item.arguments)\n",
        "        result = square(args['number'])  # equivalent to square(number=args[\"number\"])\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-Ee9dyXgf-H",
        "outputId": "c8932a84-5f26-4185-b675-cb5001d90a9a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Weather Agent"
      ],
      "metadata": {
        "id": "fUroEv3Yndbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First, we define the real \"get_weather\" function we will use\n",
        "\n",
        "This uses the Open-meteo API, a free API that allows us to get weather for any latitute and longtitute."
      ],
      "metadata": {
        "id": "IOdzOHuEnt83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weather(latitude, longitude):\n",
        "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
        "    data = response.json()\n",
        "    return data['current']['temperature_2m']"
      ],
      "metadata": {
        "id": "xtrdOc01n1sS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Then, we write the *schema* for the function.\n",
        "\n",
        "It is okay if you do not understand this -- OpenAI has a tool to help us do this we will cover next time."
      ],
      "metadata": {
        "id": "jlcqLh_8oH9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [{\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Get current temperature for a given location.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"latitude\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Latitude of desired location\"\n",
        "            },\n",
        "            \"longitude\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Longitude of desired location\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"latitude\",\"longitude\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}]\n",
        "\n"
      ],
      "metadata": {
        "id": "cXOo9MP7ndP7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Then, we set up the chat loop:"
      ],
      "metadata": {
        "id": "FkHCgt8Aocbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Get user input\n",
        "user_query = input(\"Ask the agent anything (weather or unrelated): \")\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=user_query,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "output = response.output[1]\n",
        "\n",
        "if output.type == \"function_call\":\n",
        "    print(\"Tool call detected!\")\n",
        "    tool_call = output\n",
        "    args = json.loads(tool_call.arguments)\n",
        "    result = get_weather(**args)\n",
        "    print(f\"Temperature: {result}°C\")\n",
        "else:\n",
        "    print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdaTOd_LhXEv",
        "outputId": "09f19721-776d-4f37-90c7-4b9a69877e3d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask the agent anything (weather or unrelated): what is the temperature in boston?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = response.output[1]\n",
        "\n",
        "if output.type == \"function_call\":\n",
        "    print(\"Tool call detected!\")\n",
        "    tool_call = output\n",
        "    args = json.loads(tool_call.arguments)\n",
        "    result = get_weather(**args)\n",
        "    print(f\"Temperature: {result}°C\")\n",
        "else:\n",
        "    print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scF4O8NOpcbW",
        "outputId": "bf34d794-1626-45d6-d658-dc2bf4e5ad06"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call detected!\n",
            "Temperature: 5.2°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Agent with loops"
      ],
      "metadata": {
        "id": "4i_M-oUleiSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def get_weather(latitude, longitude):\n",
        "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
        "    data = response.json()\n",
        "    return data['current']['temperature_2m']\n",
        "\n",
        "def square(number):\n",
        "  return number**2\n",
        "\n",
        "\n",
        "###### Model's version of the functions ######\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get current temperature for a given location.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"latitude\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Latitude of desired location\"\n",
        "                },\n",
        "                \"longitude\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Longitude of desired location\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"latitude\", \"longitude\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"square\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"number\": { \"type\": \"number\" }\n",
        "        },\n",
        "        \"required\": [\"number\"]\n",
        "    }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# General function for calling our functions\n",
        "def call_function(name, args):\n",
        "    if name == \"get_weather\":\n",
        "        return get_weather(**args)\n",
        "    elif name == \"square\":\n",
        "        return square(**args)\n",
        "    else:\n",
        "        return f\"No such function: {name}\"\n",
        "\n",
        "\n",
        "###### UI ######\n",
        "\n",
        "# Step 2: Get user input\n",
        "user_query = input(\"Ask the agent something: \")\n",
        "messages = [{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "while True:\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        input=messages,\n",
        "        tools=tools\n",
        "    )\n",
        "    output = response.output\n",
        "\n",
        "    if output and output[0].type == \"function_call\":\n",
        "        tool_call = output[0]\n",
        "        print(f\"\\nTool call detected: {tool_call.name}\")\n",
        "        args = json.loads(tool_call.arguments)\n",
        "\n",
        "        result = call_function(tool_call.name, args)\n",
        "\n",
        "        if isinstance(result, dict):\n",
        "            result = json.dumps(result)\n",
        "\n",
        "        # Append both the call and the result\n",
        "        messages.append(tool_call.model_dump())\n",
        "\n",
        "        messages.append({\n",
        "            \"type\": \"function_call_output\",\n",
        "            \"call_id\": tool_call.call_id,\n",
        "            \"output\": str(result)\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        print(\"\\nAgent response:\\n\")\n",
        "        print(response.output_text)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkuxafZ0fZfZ",
        "outputId": "727a98d2-cb40-43b7-81fc-b579c78eb326"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask the agent something: What is the temperature in boston squared?\n",
            "\n",
            "Tool call detected: get_weather\n",
            "\n",
            "Tool call detected: square\n",
            "\n",
            "Agent response:\n",
            "\n",
            "The current temperature in Boston is 2.1°C. When squared, this gives you 4.41.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: News sentiment plotter (if time)\n",
        "\n",
        "\n",
        "Note this will not work if you do not have a Guardian API key. For more information on how to get a Guardian API key, click the link here: https://open-platform.theguardian.com/"
      ],
      "metadata": {
        "id": "-z0PvbjHfZ3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "GUARDIAN_API_KEY = \"\"  # Replace with your Guardian API key\n",
        "\n",
        "###### Defining real functions for US to exectute ######\n",
        "def get_news_articles(query: str, order_by: str, page_size: int, output_path: str) -> str:\n",
        "    url = \"https://content.guardianapis.com/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"order-by\": order_by,\n",
        "        \"page-size\": page_size,\n",
        "        \"show-fields\": \"bodyText\",\n",
        "        \"api-key\": GUARDIAN_API_KEY\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    data = response.json()\n",
        "    results = data.get(\"response\", {}).get(\"results\", [])\n",
        "\n",
        "    articles = []\n",
        "    for item in results:\n",
        "        fields = item.get(\"fields\", {})\n",
        "        body = fields.get(\"bodyText\", \"\")\n",
        "        date = item.get(\"webPublicationDate\", \"\")\n",
        "        articles.append({\"date\": date, \"article_text\": body})\n",
        "\n",
        "    df = pd.DataFrame(articles)\n",
        "    df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Saved {len(df)} articles to {output_path}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_weather(latitude, longitude):\n",
        "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
        "    data = response.json()\n",
        "    return data['current']['temperature_2m']\n",
        "\n",
        "def analyze_sentiment(sentiments, output_path):\n",
        "    try:\n",
        "        df = pd.DataFrame(sentiments)\n",
        "\n",
        "        if not all(1 <= s <= 10 for s in df[\"sentiment\"]):\n",
        "            return \"Error: Sentiment scores must be between 1 and 10.\"\n",
        "\n",
        "        df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "        print(f\"Saved sentiment analysis to {output_path}\")\n",
        "        return f\"Saved sentiment analysis to {output_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error saving sentiment output: {str(e)}\"\n",
        "\n",
        "def graph_data(csv_path: str, x_column: str, y_column: str, title: str, x_label: str, y_label: str) -> str:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        if x_column not in df.columns or y_column not in df.columns:\n",
        "            return f\"Error: Columns '{x_column}' and/or '{y_column}' not found in {csv_path}.\"\n",
        "\n",
        "        # Convert date to full datetime\n",
        "        df[x_column] = pd.to_datetime(df[x_column], errors='coerce')\n",
        "        df = df.dropna(subset=[x_column, y_column])\n",
        "        df = df.sort_values(by=x_column)\n",
        "\n",
        "        # Plot each entry (no aggregation)\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(df[x_column], df[y_column], marker='o', linestyle='-', alpha=0.7)\n",
        "\n",
        "        plt.title(title)\n",
        "        plt.xlabel(x_label)\n",
        "        plt.ylabel(y_label)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        output_image_path = csv_path.replace(\".csv\", \"_graph.png\")\n",
        "        plt.savefig(output_image_path)\n",
        "        plt.close()\n",
        "\n",
        "        return f\"Graph saved to {output_image_path}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Graphing error: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "###### Model's version of the functions ######\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get current temperature for a given location.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"latitude\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Latitude of desired location\"\n",
        "                },\n",
        "                \"longitude\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Longitude of desired location\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"latitude\", \"longitude\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"get_news_articles\",\n",
        "        \"description\": \"Fetch news articles from The Guardian API and save them to a CSV.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Search query, e.g., 'climate change'\"\n",
        "                },\n",
        "                \"order_by\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"newest\", \"oldest\", \"relevance\"],\n",
        "                    \"description\": \"How to sort the articles\"\n",
        "                },\n",
        "                \"page_size\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"How many articles to return (max 200)\"\n",
        "                },\n",
        "                \"output_path\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"File path where the articles will be saved as CSV\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"query\", \"order_by\", \"page_size\", \"output_path\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"analyze_sentiment\",\n",
        "        \"description\": \"Analyze sentiment of article texts on a scale from 1 (negative) to 10 (positive), and save results as a CSV.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"sentiments\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"datetime\": {\"type\": \"string\"},\n",
        "                            \"sentiment\": {\n",
        "                                \"type\": \"integer\",\n",
        "                                \"enum\": [1,2,3,4,5,6,7,8,9,10],\n",
        "                                \"description\": \"Sentiment score: 1 (very negative) to 10 (very positive)\"\n",
        "                            }\n",
        "                        },\n",
        "                        \"required\": [\"datetime\",  \"sentiment\"],\n",
        "                        \"additionalProperties\": False\n",
        "                    },\n",
        "                    \"description\": \"Each entry contains the article snippet, datetime, and its sentiment score. Do NOT change the datetimes.\"\n",
        "                },\n",
        "                \"output_path\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"CSV file path to save sentiment results\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"sentiments\", \"output_path\"],\n",
        "            \"additionalProperties\": False\n",
        "        },\n",
        "        \"strict\": True\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"graph_data\",\n",
        "        \"description\": \"Generate a graph from a CSV file.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"csv_path\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Path to the CSV file containing the data\"\n",
        "                },\n",
        "                \"x_column\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Column name to use as x-axis\"\n",
        "                },\n",
        "                \"y_column\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Column name to use as y-axis\"\n",
        "                },\n",
        "                \"title\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Title of the graph\"\n",
        "                },\n",
        "                \"x_label\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Label for the x-axis\"\n",
        "                },\n",
        "                \"y_label\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Label for the y-axis\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"csv_path\", \"x_column\", \"y_column\", \"title\", \"x_label\", \"y_label\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# General function for calling our functions\n",
        "def call_function(name, args):\n",
        "    if name == \"get_weather\":\n",
        "        return get_weather(**args)\n",
        "    elif name == \"get_news_articles\":\n",
        "        return get_news_articles(**args)\n",
        "    elif name == \"graph_data\":\n",
        "        return graph_data(**args)\n",
        "    elif name == \"analyze_sentiment\":\n",
        "        return analyze_sentiment(**args)\n",
        "    else:\n",
        "        return f\"No such function: {name}\"\n",
        "\n",
        "\n",
        "###### UI ######\n",
        "\n",
        "# Step 2: Get user input\n",
        "user_query = input(\"Ask the agent something: \")\n",
        "messages = [{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "while True:\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        input=messages,\n",
        "        tools=tools\n",
        "    )\n",
        "    output = response.output\n",
        "\n",
        "    if output and output[0].type == \"function_call\":\n",
        "        tool_call = output[0]\n",
        "        print(f\"\\nTool call detected: {tool_call.name}\")\n",
        "        args = json.loads(tool_call.arguments)\n",
        "\n",
        "        result = call_function(tool_call.name, args)\n",
        "\n",
        "        if isinstance(result, dict):\n",
        "            result = json.dumps(result)\n",
        "\n",
        "        # Append both the call and the result\n",
        "        messages.append(tool_call.model_dump())\n",
        "\n",
        "        messages.append({\n",
        "            \"type\": \"function_call_output\",\n",
        "            \"call_id\": tool_call.call_id,\n",
        "            \"output\": str(result)\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        print(\"\\nAgent response:\\n\")\n",
        "        print(response.output_text)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MjYzePUmem9e",
        "outputId": "be181e46-c689-4b8d-b55f-e80978be8f93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4161707586.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;31m# Step 2: Get user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ask the agent something: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjBIlUD2fiJM",
        "outputId": "f75e0de7-c898-4499-8bd7-ad31af5ab67e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(id='resp_092fb5c0dbab0c84006916a758f3e88190870910aeafb9945b', created_at=1763092313.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_092fb5c0dbab0c84006916a759e7e881908dab873369074c54', content=[ResponseOutputText(annotations=[], text='Here is a plot of the sentiment scores of the 10 most recent articles about Harvard over time:\\n\\n- The x-axis shows the dates of the articles.\\n- The y-axis shows the sentiment scores (1 = very negative, 10 = very positive).\\n\\nWould you like to see or download the graph image?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_weather', parameters={'type': 'object', 'properties': {'latitude': {'type': 'string', 'description': 'Latitude of desired location'}, 'longitude': {'type': 'string', 'description': 'Longitude of desired location'}}, 'required': ['latitude', 'longitude'], 'additionalProperties': False}, strict=True, type='function', description='Get current temperature for a given location.'), FunctionTool(name='get_news_articles', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': \"Search query, e.g., 'climate change'\"}, 'order_by': {'type': 'string', 'enum': ['newest', 'oldest', 'relevance'], 'description': 'How to sort the articles'}, 'page_size': {'type': 'integer', 'description': 'How many articles to return (max 200)'}, 'output_path': {'type': 'string', 'description': 'File path where the articles will be saved as CSV'}}, 'required': ['query', 'order_by', 'page_size', 'output_path'], 'additionalProperties': False}, strict=True, type='function', description='Fetch news articles from The Guardian API and save them to a CSV.'), FunctionTool(name='analyze_sentiment', parameters={'type': 'object', 'properties': {'sentiments': {'type': 'array', 'items': {'type': 'object', 'properties': {'datetime': {'type': 'string'}, 'sentiment': {'type': 'integer', 'enum': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'description': 'Sentiment score: 1 (very negative) to 10 (very positive)'}}, 'required': ['datetime', 'sentiment'], 'additionalProperties': False}, 'description': 'Each entry contains the article snippet, datetime, and its sentiment score. Do NOT change the datetimes.'}, 'output_path': {'type': 'string', 'description': 'CSV file path to save sentiment results'}}, 'required': ['sentiments', 'output_path'], 'additionalProperties': False}, strict=True, type='function', description='Analyze sentiment of article texts on a scale from 1 (negative) to 10 (positive), and save results as a CSV.'), FunctionTool(name='graph_data', parameters={'type': 'object', 'properties': {'csv_path': {'type': 'string', 'description': 'Path to the CSV file containing the data'}, 'x_column': {'type': 'string', 'description': 'Column name to use as x-axis'}, 'y_column': {'type': 'string', 'description': 'Column name to use as y-axis'}, 'title': {'type': 'string', 'description': 'Title of the graph'}, 'x_label': {'type': 'string', 'description': 'Label for the x-axis'}, 'y_label': {'type': 'string', 'description': 'Label for the y-axis'}}, 'required': ['csv_path', 'x_column', 'y_column', 'title', 'x_label', 'y_label'], 'additionalProperties': False}, strict=True, type='function', description='Generate a graph from a CSV file.')], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=1058, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=64, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1122), user=None, billing={'payer': 'developer'}, prompt_cache_retention=None, store=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68OI2XERfirK",
        "outputId": "645c07dc-2cb8-431d-9949-637c51bd1c53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': 'Generate me a plot of the sentiment scores of the 10 most recent articles about harvard over tine'},\n",
              " {'arguments': '{\"query\":\"harvard\",\"order_by\":\"newest\",\"page_size\":10,\"output_path\":\"harvard_articles.csv\"}',\n",
              "  'call_id': 'call_tHqk68kUshoorFTl3xkndQLS',\n",
              "  'name': 'get_news_articles',\n",
              "  'type': 'function_call',\n",
              "  'id': 'fc_092fb5c0dbab0c84006916a74f07848190b711f6162b963141',\n",
              "  'status': 'completed'},\n",
              " {'type': 'function_call_output',\n",
              "  'call_id': 'call_tHqk68kUshoorFTl3xkndQLS',\n",
              "  'output': '                   date                                       article_text\\n0  2025-11-12T17:29:42Z  In these turbulent times, we take small joys w...\\n1  2025-11-12T17:20:47Z  A court in Beijing is expected to rule on Thur...\\n2  2025-11-10T12:00:48Z  In the afterglow of electoral triumph, hope sp...\\n3  2025-11-09T10:00:29Z  Across the country, Donald Trump’s crackdown o...\\n4  2025-11-07T15:03:52Z  When Zohran Mamdani was elected as New York Ci...\\n5  2025-11-07T12:00:40Z  Nancy Pelosi’s announcement that, after nearly...\\n6  2025-11-07T10:01:22Z  In the late 2010s, Noam Shuster Eliassi was wo...\\n7  2025-11-06T10:00:05Z  The morning after Zohran Mamdani’s startling m...\\n8  2025-11-04T10:00:27Z  In October, the Washington Post reported that ...\\n9  2025-11-03T13:08:15Z  Good morning. The collective wealth of the top...'},\n",
              " {'arguments': '{\"sentiments\":[{\"datetime\":\"2025-11-12T17:29:42Z\",\"sentiment\":6},{\"datetime\":\"2025-11-12T17:20:47Z\",\"sentiment\":5},{\"datetime\":\"2025-11-10T12:00:48Z\",\"sentiment\":7},{\"datetime\":\"2025-11-09T10:00:29Z\",\"sentiment\":4},{\"datetime\":\"2025-11-07T15:03:52Z\",\"sentiment\":8},{\"datetime\":\"2025-11-07T12:00:40Z\",\"sentiment\":5},{\"datetime\":\"2025-11-07T10:01:22Z\",\"sentiment\":6},{\"datetime\":\"2025-11-06T10:00:05Z\",\"sentiment\":7},{\"datetime\":\"2025-11-04T10:00:27Z\",\"sentiment\":3},{\"datetime\":\"2025-11-03T13:08:15Z\",\"sentiment\":6}],\"output_path\":\"harvard_sentiments.csv\"}',\n",
              "  'call_id': 'call_fwJ0u81QaNiaOaqXHllYDeDo',\n",
              "  'name': 'analyze_sentiment',\n",
              "  'type': 'function_call',\n",
              "  'id': 'fc_092fb5c0dbab0c84006916a7534ddc8190aba399a828ad8921',\n",
              "  'status': 'completed'},\n",
              " {'type': 'function_call_output',\n",
              "  'call_id': 'call_fwJ0u81QaNiaOaqXHllYDeDo',\n",
              "  'output': 'Saved sentiment analysis to harvard_sentiments.csv'},\n",
              " {'arguments': '{\"csv_path\":\"harvard_sentiments.csv\",\"x_column\":\"datetime\",\"y_column\":\"sentiment\",\"title\":\"Sentiment Scores of Recent Harvard Articles Over Time\",\"x_label\":\"Date\",\"y_label\":\"Sentiment Score\"}',\n",
              "  'call_id': 'call_sUjd8G6vbdYr5xd692SxWdD5',\n",
              "  'name': 'graph_data',\n",
              "  'type': 'function_call',\n",
              "  'id': 'fc_092fb5c0dbab0c84006916a7578fcc8190847c0ad2658516c4',\n",
              "  'status': 'completed'},\n",
              " {'type': 'function_call_output',\n",
              "  'call_id': 'call_sUjd8G6vbdYr5xd692SxWdD5',\n",
              "  'output': 'Graph saved to harvard_sentiments_graph.png'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}
