{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "DPI681_VectorDB_And_RAG_Activities.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DPI681 — Vector DB & RAG Activities (Colab Notebook)\n",
        "\n",
        "This notebook consolidates three activities into a single, reproducible workflow:\n",
        "1. **Bulk Image Analysis** — multimodal prompts over a set of image URLs, results saved to CSV.\n",
        "2. **RAG (One-Shot)** — retrieve context from a FAISS index and answer a single legal question.\n",
        "3. **RAG (Chat)** — iterative chat with retrieval for Massachusetts real-estate law.\n",
        "\n",
        "**Key decisions**  \n",
        "- Uses **OpenAI Responses API** (not Chat Completions).  \n",
        "- All tabular work is done with **Polars** (no pandas).  \n",
        "- API key is stored and read from Colab **Secrets** (`google.colab.userdata`) — not `os.environ`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup — API Key in Colab Secrets\n",
        "\n",
        "We use Colab's `google.colab.userdata` to persist your `OPENAI_API_KEY`.  \n",
        "If it's missing, you'll be prompted (input is hidden) and your key will be saved to Secrets for future sessions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "\n",
        "key = userdata.get('OPENAI_API_KEY')\n",
        "if not key:\n",
        "    print(\"No OPENAI_API_KEY found in Colab Secrets.\")\n",
        "    _k = getpass(\"Enter your OPENAI_API_KEY (input hidden): \")\n",
        "    if not _k or not _k.strip():\n",
        "        raise ValueError(\"No key provided. Rerun this cell and enter a valid key.\")\n",
        "    userdata.set('OPENAI_API_KEY', _k.strip())\n",
        "    print(\"Saved OPENAI_API_KEY to Colab Secrets.\")\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY is set in Colab Secrets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup — Install Dependencies\n",
        "\n",
        "Installs runtime libraries. We pin FAISS to CPU flavor for portability. Also installs `gdown` to fetch the shared folder by ID if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip -q install polars==1.* faiss-cpu openai==1.* tqdm pillow gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup — Mount Drive or Auto-Download Shared Folder\n",
        "\n",
        "The class folder is shared at:  \n",
        "`https://drive.google.com/drive/folders/1XTbuR5vcz7FsikBRPh1SXwFjbUY4mx46`\n",
        "\n",
        "- We **first** try to use the mounted Drive path:  \n",
        "  `/content/drive/MyDrive/Teaching/DPI681 Materials/RAG Materials`  \n",
        "- If it’s not found (e.g., students didn’t add a shortcut to Drive), we **auto-download** the folder contents using its ID into `/content/class_materials`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preferred path if students added the shared folder (or a shortcut) to their MyDrive:\n",
        "CLASS_FOLDER = \"/content/drive/MyDrive/Teaching/DPI681 Materials/RAG Materials\"\n",
        "\n",
        "# Fallback: download shared folder by ID (read-only) into local runtime.\n",
        "FOLDER_ID = \"1XTbuR5vcz7FsikBRPh1SXwFjbUY4mx46\"\n",
        "LOCAL_FALLBACK = \"/content/class_materials\"\n",
        "\n",
        "def ensure_class_folder():\n",
        "    global CLASS_FOLDER\n",
        "    if os.path.exists(CLASS_FOLDER):\n",
        "        print(\"Using mounted class folder:\", CLASS_FOLDER)\n",
        "        return CLASS_FOLDER\n",
        "    print(\"Mounted path not found. Downloading shared folder by ID...\")\n",
        "    os.makedirs(LOCAL_FALLBACK, exist_ok=True)\n",
        "    # gdown will create a subdir named by the folder; normalize to the first/only dir if needed\n",
        "    !gdown --folder \"$FOLDER_ID\" -O \"$LOCAL_FALLBACK\" -q\n",
        "    # Try to detect the actual directory with our expected files.\n",
        "    candidates = []\n",
        "    for root, dirs, files in os.walk(LOCAL_FALLBACK):\n",
        "        if \"images.csv\" in files or (\"faiss_index.bin\" in files and \"metadata.json\" in files):\n",
        "            candidates.append(root)\n",
        "    if candidates:\n",
        "        candidates.sort(key=len)\n",
        "        CLASS_FOLDER = candidates[0]\n",
        "        print(\"Using downloaded class folder:\", CLASS_FOLDER)\n",
        "        return CLASS_FOLDER\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Downloaded folder does not contain expected files. Please add the shared folder to your Drive or adjust paths.\")\n",
        "\n",
        "CLASS_FOLDER = ensure_class_folder()\n",
        "\n",
        "# Student output location\n",
        "STUDENT_WORKDIR = \"/content/drive/MyDrive/dpi681_student_work\"\n",
        "os.makedirs(STUDENT_WORKDIR, exist_ok=True)\n",
        "print(\"STUDENT_WORKDIR:\", STUDENT_WORKDIR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Common imports\n",
        "import os, json\n",
        "from typing import List, Dict, Any\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY missing from Colab Secrets. Rerun the secrets cell.\")\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Activity 1 — Bulk Image Analysis (Multimodal)\n",
        "\n",
        "**Goal:** send a text+image prompt to the OpenAI Responses API for each image in `images.csv` and save results.\n",
        "\n",
        "**Iterate on the prompt** by editing `PROMPT_TEXT` and re-running the processing cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "IMAGES_CSV = os.path.join(CLASS_FOLDER, \"images.csv\")       # must include columns: image_id, url\n",
        "RESULTS_CSV = os.path.join(STUDENT_WORKDIR, \"images_analysis_results.csv\")\n",
        "MODEL_VISION = \"gpt-4o-mini\"\n",
        "\n",
        "# Your prompt: edit freely and rerun\n",
        "PROMPT_TEXT = \"Return one word capturing the sentiment of the image.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the dataset (Polars) and validate columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if not os.path.exists(IMAGES_CSV):\n",
        "    raise FileNotFoundError(f\"images.csv not found at {IMAGES_CSV}. Check the shared folder or fallback download.\")\n",
        "\n",
        "df_images = pl.read_csv(IMAGES_CSV)\n",
        "required_cols = {\"image_id\", \"url\"}\n",
        "missing = required_cols - set(df_images.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"images.csv must have columns {required_cols}, missing: {missing}\")\n",
        "\n",
        "df_images.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process images with the Responses API\n",
        "Sends a single user message containing text **and** an image URL per row. Saves a Polars DataFrame to CSV in your `STUDENT_WORKDIR`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "results: List[Dict[str, Any]] = []\n",
        "\n",
        "for row in tqdm(df_images.iter_rows(named=True), total=df_images.height, desc=\"Processing Images\"):\n",
        "    image_id = row[\"image_id\"]\n",
        "    image_url = row[\"url\"]\n",
        "\n",
        "    try:\n",
        "        resp = client.responses.create(\n",
        "            model=MODEL_VISION,\n",
        "            input=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"input_text\", \"text\": PROMPT_TEXT},\n",
        "                    {\"type\": \"input_image\", \"image_url\": str(image_url)},\n",
        "                ],\n",
        "            }],\n",
        "        )\n",
        "        output_text = (resp.output_text or \"\").strip()\n",
        "    except Exception as e:\n",
        "        output_text = f\"[ERROR] {e}\"\n",
        "\n",
        "    results.append({\"image_id\": image_id, \"url\": image_url, \"output_text\": output_text})\n",
        "\n",
        "pl.DataFrame(results).write_csv(RESULTS_CSV)\n",
        "print(f\"Image analysis complete. Results saved to: {RESULTS_CSV}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Activity 2 — Legal Assistant with RAG (One-Shot)\n",
        "\n",
        "**Pipeline**\n",
        "1. Load FAISS index and `metadata.json` (prebuilt).\n",
        "2. Embed the query (`text-embedding-3-small`).\n",
        "3. Retrieve top-K documents and format brief citations.\n",
        "4. Call the **Responses API** with a system prompt + retrieved context + user question.  \n",
        "**Model replies in plain text (no markdown)** and cites as `Chapter [X] Section [Y]` with a link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "FAISS_INDEX_FILE = os.path.join(CLASS_FOLDER, \"faiss_index.bin\")\n",
        "METADATA_FILE = os.path.join(CLASS_FOLDER, \"metadata.json\")\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "GEN_MODEL = \"gpt-4o\"\n",
        "TOP_K = 3\n",
        "\n",
        "if not os.path.exists(FAISS_INDEX_FILE) or not os.path.exists(METADATA_FILE):\n",
        "    raise FileNotFoundError(\"Missing FAISS index or metadata.json in CLASS_FOLDER.\")\n",
        "\n",
        "faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "with open(METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "def get_embedding(text: str) -> np.ndarray:\n",
        "    txt = text if isinstance(text, str) else str(text)\n",
        "    txt = txt[:8150]\n",
        "    r = client.embeddings.create(model=EMBEDDING_MODEL, input=txt)\n",
        "    emb = r.data[0].embedding\n",
        "    return np.asarray(emb, dtype=np.float32)\n",
        "\n",
        "def retrieve_context(query: str, top_k: int = TOP_K) -> str:\n",
        "    q = get_embedding(query)\n",
        "    q = np.expand_dims(q, axis=0)\n",
        "    D, I = faiss_index.search(q, top_k)\n",
        "    lines = []\n",
        "    for idx in I[0]:\n",
        "        if 0 <= idx < len(metadata):\n",
        "            doc = metadata[idx]\n",
        "            citation = f\"(Chapter {doc.get('chapter','?')} Section {doc.get('section','?')}, {doc.get('link','No link')})\"\n",
        "            snippet = (doc.get('full_text','').replace('\\n',' ')[:200]).strip()\n",
        "            lines.append(f\"{citation}: {snippet}\")\n",
        "    return \"Retrieved context:\\n\" + \"\\n\".join(lines) + \"\\n\" if lines else \"\"\n",
        "\n",
        "BASE_SYSTEM_PROMPT = (\n",
        "    \"You are a legal assistant helping non-lawyers understand Massachusetts real-estate law. \"\n",
        "    \"You are not a lawyer and cannot provide legal advice. \"\n",
        "    \"Point users to the relevant section of the law and explain how it applies in plain English. \"\n",
        "    \"Do not return your replies in markdown, only plain text. \"\n",
        "    \"Cite sources as 'Chapter [Chapter] Section [Section]' with a link at the end.\"\n",
        ")\n",
        "\n",
        "def ask_once(question: str) -> str:\n",
        "    ctx = retrieve_context(question)\n",
        "    sys_prompt = BASE_SYSTEM_PROMPT + \"\\n\" + ctx\n",
        "    resp = client.responses.create(\n",
        "        model=GEN_MODEL,\n",
        "        input=[\n",
        "            {\"role\":\"system\",\"content\":sys_prompt},\n",
        "            {\"role\":\"user\",\"content\":question}\n",
        "        ],\n",
        "    )\n",
        "    return (resp.output_text or \"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try it (one-shot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "q = \"What are the notice requirements for eviction in Massachusetts?\"\n",
        "print(ask_once(q))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Activity 3 — Legal Assistant with RAG (Chat)\n",
        "\n",
        "Maintains a small conversation history and augments each turn with retrieved context.  \n",
        "Streaming omitted for simplicity; we return final text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "conversation_history: List[Dict[str,str]] = []\n",
        "\n",
        "CHAT_SYSTEM_PROMPT = (\n",
        "    \"You are a legal assistant tasked with helping non-lawyers understand their questions about Massachusetts real-estate law. \"\n",
        "    \"You do not help with any other requests. \"\n",
        "    \"You are not a lawyer and cannot provide legal advice. \"\n",
        "    \"Use retrieved context when available. \"\n",
        "    \"Reply in plain text (no markdown). \"\n",
        "    \"Cite as 'Chapter [Chapter] Section [Section]' with the link at the end.\"\n",
        ")\n",
        "\n",
        "def chat_once(user_text: str, max_context_msgs: int = 10) -> str:\n",
        "    ctx = retrieve_context(user_text)\n",
        "    sys_prompt = CHAT_SYSTEM_PROMPT + \"\\n\" + ctx\n",
        "    msgs = [{\"role\":\"system\",\"content\":sys_prompt}] + conversation_history[-max_context_msgs:] + [\n",
        "        {\"role\":\"user\",\"content\":user_text}\n",
        "    ]\n",
        "    r = client.responses.create(model=GEN_MODEL, input=msgs)\n",
        "    out = (r.output_text or \"\").strip()\n",
        "    conversation_history.append({\"role\":\"user\",\"content\":user_text})\n",
        "    conversation_history.append({\"role\":\"assistant\",\"content\":out})\n",
        "    return out\n",
        "\n",
        "def chat():\n",
        "    print(\"RAG Chat — type 'exit' to quit.\\n\")\n",
        "    while True:\n",
        "        try:\n",
        "            u = input(\"> \").strip()\n",
        "        except EOFError:\n",
        "            break\n",
        "        if u.lower() in (\"exit\",\"quit\"):\n",
        "            print(\"Goodbye.\")\n",
        "            break\n",
        "        reply = chat_once(u)\n",
        "        print(\"\\n\" + reply + \"\\n\")\n",
        "\n",
        "# Uncomment to start an interactive chat session:\n",
        "# chat()"
      ]
    }
  ]
}