{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "DPI681_VectorDB_And_RAG_Activities.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl9b3vY65sbF"
      },
      "source": [
        "# Section 3 -- Image analysis & RAG"
      ],
      "id": "gl9b3vY65sbF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDCLVW_B5sbG"
      },
      "source": [
        "## Setup"
      ],
      "id": "HDCLVW_B5sbG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SCZxJivV5sbH"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google.colab.userdata import SecretNotFoundError\n",
        "from getpass import getpass\n",
        "\n",
        "try:\n",
        "    key = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"OPENAI_API_KEY is set in Colab Secrets.\")\n",
        "except SecretNotFoundError:\n",
        "    print(\"No OPENAI_API_KEY found in Colab Secrets.\")\n",
        "    print(\"Open the 'Secrets' tab on the left (the key icon')\")\n",
        "    print(\"Click 'Add new secret'\")\n",
        "    print(\"Set the name to OPENAI_API_KEY\")\n",
        "    print(\"Set the value to your API key\")\n",
        "    print(\"Click on the 'notebook access' toggle to turn it on\")"
      ],
      "id": "SCZxJivV5sbH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmES3lc15sbH"
      },
      "source": [
        "## Setup — Install Dependencies\n",
        "\n",
        "Installs runtime libraries. Also installs `gdown` to fetch the shared folder by ID if needed."
      ],
      "id": "SmES3lc15sbH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gnwyDuT85sbH"
      },
      "execution_count": 47,
      "outputs": [],
      "source": [
        "!pip -q install polars==1.* faiss-cpu openai==1.* tqdm pillow gdown"
      ],
      "id": "gnwyDuT85sbH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQgT8HMD5sbI"
      },
      "source": [
        "## Setup — Mount Drive or Auto-Download Shared Folder\n",
        "\n",
        "The class folder is shared at:  \n",
        "`https://drive.google.com/drive/folders/1XTbuR5vcz7FsikBRPh1SXwFjbUY4mx46`\n",
        "\n",
        "This script will download the materials in that folder to your Google Drive. You will see a folder appear called `DPI681 Section Materials` in your drive. If you would like to put it elsewhere, change the file path in `STUDENT_WORKDIR`."
      ],
      "id": "bQgT8HMD5sbI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cellView": "form",
        "id": "DyildHK65sbI"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Preferred path if students added the shared folder (or a shortcut) to their MyDrive:\n",
        "CLASS_FOLDER = \"/content/drive/MyDrive/Teaching/DPI681 Materials/RAG Materials\"\n",
        "\n",
        "# Fallback: download shared folder by ID (read-only) into local runtime.\n",
        "FOLDER_ID = \"1XTbuR5vcz7FsikBRPh1SXwFjbUY4mx46\"\n",
        "LOCAL_FALLBACK = \"/content/class_materials\"\n",
        "\n",
        "def ensure_class_folder():\n",
        "    global CLASS_FOLDER\n",
        "    os.makedirs(LOCAL_FALLBACK, exist_ok=True)\n",
        "    # gdown will create a subdir named by the folder; normalize to the first/only dir if needed\n",
        "    !gdown --folder \"$FOLDER_ID\" -O \"$LOCAL_FALLBACK\" -q\n",
        "    # Try to detect the actual directory with our expected files.\n",
        "    candidates = []\n",
        "    for root, dirs, files in os.walk(LOCAL_FALLBACK):\n",
        "        if \"images.csv\" in files or (\"faiss_index.bin\" in files and \"metadata.json\" in files):\n",
        "            candidates.append(root)\n",
        "    if candidates:\n",
        "        candidates.sort(key=len)\n",
        "        CLASS_FOLDER = candidates[0]\n",
        "        print(\"Using downloaded class folder:\", CLASS_FOLDER)\n",
        "        return CLASS_FOLDER\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Downloaded folder does not contain expected files. Please add the shared folder to your Drive or adjust paths.\")\n",
        "\n",
        "CLASS_FOLDER = ensure_class_folder()\n"
      ],
      "id": "DyildHK65sbI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Student output location (Change this if you would like)\n",
        "STUDENT_WORKDIR = \"/content/drive/MyDrive/DPI681 Section Materials\"\n",
        "\n",
        "os.makedirs(STUDENT_WORKDIR, exist_ok=True)\n",
        "print(\"STUDENT_WORKDIR:\", STUDENT_WORKDIR)"
      ],
      "metadata": {
        "id": "u-GTpKwC8VEA"
      },
      "id": "u-GTpKwC8VEA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cellView": "form",
        "id": "uvC0mBl65sbI"
      },
      "execution_count": 50,
      "outputs": [],
      "source": [
        "# @title\n",
        "# Common imports\n",
        "import os, json\n",
        "from typing import List, Dict, Any\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY missing from Colab Secrets. Rerun the secrets cell.\")\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "id": "uvC0mBl65sbI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehiotb065sbJ"
      },
      "source": [
        "---\n",
        "## Activity 1 — Bulk Image Analysis (Multimodal)\n",
        "\n",
        "**Goal:** send a text+image prompt to the OpenAI Responses API for each image in `images.csv` and save results.\n"
      ],
      "id": "Ehiotb065sbJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCk5-ypL5sbJ"
      },
      "execution_count": 51,
      "outputs": [],
      "source": [
        "IMAGES_CSV = os.path.join(CLASS_FOLDER, \"images.csv\")       # must include columns: image_id, url\n",
        "RESULTS_CSV = os.path.join(STUDENT_WORKDIR, \"images_analysis_results.csv\")\n",
        "MODEL = \"gpt-5-mini\""
      ],
      "id": "ZCk5-ypL5sbJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlx3QQK05sbJ"
      },
      "source": [
        "### Load the dataset (Polars) and validate columns"
      ],
      "id": "vlx3QQK05sbJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qq4_EuxZ5sbJ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if not os.path.exists(IMAGES_CSV):\n",
        "    raise FileNotFoundError(f\"images.csv not found at {IMAGES_CSV}. Check the shared folder or fallback download.\")\n",
        "\n",
        "df_images = pl.read_csv(IMAGES_CSV)\n",
        "df_images.head(3)"
      ],
      "id": "Qq4_EuxZ5sbJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zppdwKvy5sbJ"
      },
      "source": [
        "### Process images with the Responses API\n",
        "Sends a single user message containing text **and** an image URL per row. Saves a Polars DataFrame to CSV in your `STUDENT_WORKDIR`."
      ],
      "id": "zppdwKvy5sbJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-yLHEk7g5sbJ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "results_raw: List[Dict[str, Any]] = []\n",
        "\n",
        "# Your prompt: edit freely and rerun\n",
        "PROMPT_TEXT = \"Who is in the image?\"\n",
        "\n",
        "for row in tqdm(df_images.iter_rows(named=True), total=df_images.height, desc=\"Processing Images\"):\n",
        "    image_id = row[\"image_id\"]\n",
        "    image_url = row[\"url\"]\n",
        "\n",
        "    resp = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": PROMPT_TEXT},\n",
        "                {\"type\": \"input_image\", \"image_url\": str(image_url)},\n",
        "            ],\n",
        "        }],\n",
        "    )\n",
        "    output_text = (resp.output_text or \"\").strip()\n",
        "\n",
        "    results_raw.append({\"image_id\": image_id, \"url\": image_url, \"output_text\": output_text})\n",
        "\n",
        "results = pl.DataFrame(results_raw)\n",
        "results.write_csv(RESULTS_CSV)\n",
        "print(f\"Image analysis complete. Results saved to: {RESULTS_CSV}\")"
      ],
      "id": "-yLHEk7g5sbJ"
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "b5aVlKZy_Hku"
      },
      "id": "b5aVlKZy_Hku",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.write_csv(RESULTS_CSV)"
      ],
      "metadata": {
        "id": "RbVXgoZp_tNH"
      },
      "id": "RbVXgoZp_tNH",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRlxQw885sbJ"
      },
      "source": [
        "---\n",
        "## Activity 2 — Legal Assistant with RAG (One-Shot)\n",
        "\n",
        "**Pipeline**\n",
        "1. Load FAISS index and `metadata.json` (prebuilt).\n",
        "2. Embed the query (`text-embedding-3-small`).\n",
        "3. Retrieve top-K documents and format brief citations.\n",
        "4. Call the **Responses API** with a system prompt + retrieved context + user question.  \n",
        "**Model replies** and cites as `Chapter [X] Section [Y]` with a link."
      ],
      "id": "VRlxQw885sbJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WY851z_e5sbJ"
      },
      "execution_count": 41,
      "outputs": [],
      "source": [
        "FAISS_INDEX_FILE = os.path.join(CLASS_FOLDER, \"faiss_index.bin\")\n",
        "METADATA_FILE = os.path.join(CLASS_FOLDER, \"metadata.json\")\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "GEN_MODEL = \"gpt-5-mini\"\n",
        "TOP_K = 3\n",
        "\n",
        "if not os.path.exists(FAISS_INDEX_FILE) or not os.path.exists(METADATA_FILE):\n",
        "    raise FileNotFoundError(\"Missing FAISS index or metadata.json in CLASS_FOLDER.\")\n",
        "\n",
        "faiss_index = faiss.read_index(FAISS_INDEX_FILE)\n",
        "with open(METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "def get_embedding(text: str) -> np.ndarray:\n",
        "    txt = text if isinstance(text, str) else str(text)\n",
        "    txt = txt[:8150]\n",
        "    r = client.embeddings.create(model=EMBEDDING_MODEL, input=txt)\n",
        "    emb = r.data[0].embedding\n",
        "    return np.asarray(emb, dtype=np.float32)\n",
        "\n",
        "def retrieve_context(query: str, top_k: int = TOP_K) -> str:\n",
        "    q = get_embedding(query)\n",
        "    q = np.expand_dims(q, axis=0)\n",
        "    D, I = faiss_index.search(q, top_k)\n",
        "    lines = []\n",
        "    for idx in I[0]:\n",
        "        if 0 <= idx < len(metadata):\n",
        "            doc = metadata[idx]\n",
        "            citation = f\"(Chapter {doc.get('chapter','?')} Section {doc.get('section','?')}, {doc.get('link','No link')})\"\n",
        "            text = (doc.get('full_text','').replace('\\n',' ')).strip()\n",
        "            lines.append(f\"{citation}: {text}\")\n",
        "    return \"Retrieved context:\\n\" + \"\\n\".join(lines) + \"\\n\" if lines else \"\"\n"
      ],
      "id": "WY851z_e5sbJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1K1O0X5sbJ"
      },
      "source": [
        "### Try it (one-shot)"
      ],
      "id": "-W1K1O0X5sbJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uYNQKQPK5sbK"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# System prompt to define the behavior\n",
        "BASE_SYSTEM_PROMPT = (\n",
        "    \"You are a legal assistant helping non-lawyers understand Massachusetts real-estate law. \"\n",
        "    \"You are not a lawyer and cannot provide legal advice. \"\n",
        "    \"Point users to the relevant section of the law and explain how it applies to them in an easy to understand way. \"\n",
        "    \"Do not return your replies in markdown, only plain text. \"\n",
        "    \"Cite sources as 'Chapter [Chapter] Section [Section]' with a link at the end.\"\n",
        ")\n",
        "\n",
        "q = \"What are the notice requirements for eviction in Massachusetts?\"\n",
        "\n",
        "# Get the necessary context from our vector database\n",
        "ctx = retrieve_context(q)\n",
        "\n",
        "# Add it to the prompt (+ trick we talked about last time)\n",
        "sys_prompt = BASE_SYSTEM_PROMPT + \"\\n\" + ctx\n",
        "\n",
        "# Send request to model with the actual legal code appended to the query\n",
        "resp = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=[\n",
        "        {\"role\":\"system\",\"content\":sys_prompt},\n",
        "        {\"role\":\"user\",\"content\":q}\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(resp.output_text)"
      ],
      "id": "uYNQKQPK5sbK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7PkzQ-Z5sbK"
      },
      "source": [
        "---\n",
        "## Legal Assistant with RAG (Chat)\n",
        "\n",
        "Maintains a small conversation history and augments each turn with retrieved context.  \n",
        "Streaming omitted for simplicity; we return final text."
      ],
      "id": "p7PkzQ-Z5sbK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "cellView": "form",
        "id": "9CgXl1EL5sbK"
      },
      "execution_count": 45,
      "outputs": [],
      "source": [
        "# @title\n",
        "from typing import List, Dict\n",
        "\n",
        "conversation_history: List[Dict[str,str]] = []\n",
        "\n",
        "def chat_once(user_text: str, max_context_msgs: int = 10) -> str:\n",
        "    ctx = retrieve_context(user_text)\n",
        "    sys_prompt = BASE_SYSTEM_PROMPT + \"\\n\" + ctx\n",
        "    msgs = [{\"role\":\"system\",\"content\":sys_prompt}] + conversation_history[-max_context_msgs:] + [\n",
        "        {\"role\":\"user\",\"content\":user_text}\n",
        "    ]\n",
        "    r = client.responses.create(model=MODEL, input=msgs)\n",
        "    out = (r.output_text or \"\").strip()\n",
        "    conversation_history.append({\"role\":\"user\",\"content\":user_text})\n",
        "    conversation_history.append({\"role\":\"assistant\",\"content\":out})\n",
        "    return out\n",
        "\n",
        "def chat():\n",
        "    print(\"RAG Chat With Mass Real Estate Code Bot — type 'exit' to quit.\\n\")\n",
        "    while True:\n",
        "        try:\n",
        "            u = input(\"> \").strip()\n",
        "        except EOFError:\n",
        "            break\n",
        "        if u.lower() in (\"exit\",\"quit\"):\n",
        "            print(\"Goodbye.\")\n",
        "            break\n",
        "        reply = chat_once(u)\n",
        "        print(\"\\n\" + reply + \"\\n\")"
      ],
      "id": "9CgXl1EL5sbK"
    },
    {
      "cell_type": "code",
      "source": [
        "chat()"
      ],
      "metadata": {
        "id": "Egf5XI5FGuLh"
      },
      "id": "Egf5XI5FGuLh",
      "execution_count": null,
      "outputs": []
    }
  ]
}