{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca11ff1",
      "metadata": {
        "id": "7ca11ff1"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5790c6",
      "metadata": {
        "id": "5d5790c6"
      },
      "source": [
        "CHALLENGE: Using the prompt engineering tools you learned this week, design a prompt that extracts something you might want to know about the article.\n",
        "This should be something you might want to convert into data to analyse later, like political slant, sentiment, or a rating of the article's quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe5de2a",
      "metadata": {
        "id": "ebe5de2a"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "   YOUR PROMPT HERE\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b272a60f",
      "metadata": {
        "id": "b272a60f"
      },
      "outputs": [],
      "source": [
        "# Read the article content from the file\n",
        "with open('./section-2/article.txt', 'r', encoding='utf-8') as file:\n",
        "    article_content = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bb6e4c0",
      "metadata": {
        "id": "9bb6e4c0"
      },
      "outputs": [],
      "source": [
        "# Create a chat completion request to analyze the article\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "     messages=[\n",
        "         #might need to add something here?\n",
        "        {\"role\": \"user\", \"content\": \"Analyze this article as instructed:\\n\" + article_content}\n",
        "    ],\n",
        "    #or sometihng here? does this change with what model you use?\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723f5ce4",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "723f5ce4"
      },
      "outputs": [],
      "source": [
        "# Parse the response and print the JSON object\n",
        "response_content = completion.choices[0].message.content\n",
        "print(\"The model returned:\" + response_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfca58ce",
      "metadata": {
        "id": "dfca58ce"
      },
      "source": [
        "\n",
        "# Section 2: Article Analyzer\n",
        "\n",
        "This Colab notebook analyzes the tarrif article using OpenAI's **Responses API** .\n",
        "It demonstrates **structured outputs** (JSON Schema) so you can convert model judgements into clean data (e.g., political slant, sentiment, and article quality).\n",
        "\n",
        "### What you'll learn\n",
        "- How to call the Responses API with `response_format={\"type\":\"json_schema\", ... , \"strict\": true}`.\n",
        "- How to design a robust extraction prompt with clear rubrics to reduce ambiguity.\n",
        "- How to parse and store the model's JSON into a pandas DataFrame for later analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206f5e01",
      "metadata": {
        "id": "206f5e01"
      },
      "source": [
        "\n",
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "991f7247",
      "metadata": {
        "id": "991f7247",
        "outputId": "2f7bf04b-8270-4b42-da32-afb28e9b2edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded from URL: https://raw.githubusercontent.com/calisley/dpi-681/refs/heads/main/section-2/article.txt (5,964 chars)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "#@ Title\n",
        "import requests\n",
        "import json, pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    try:\n",
        "        import getpass\n",
        "        OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key (input hidden): \").strip()\n",
        "    except Exception:\n",
        "        raise ValueError(\"Unable to capture API key input. Set os.environ['OPENAI_API_KEY'] manually.\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\"Missing API key. Please provide a valid OpenAI API key.\")\n",
        "\n",
        "# Make the key available to the SDK\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9d82917",
      "metadata": {
        "id": "b9d82917"
      },
      "source": [
        "\n",
        "## 2.0) Working with text in Python\n",
        "\n",
        "- A useful Python trick for combining strings is using the `+` sign.\n",
        "\n",
        "For example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello \" + \"World\"\n",
        "\n",
        "print(text) # -> \"Hello World\"\n"
      ],
      "metadata": {
        "id": "S328mk3L7LLr",
        "outputId": "fc7da749-0b06-416f-ef8b-cf17e7725785",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S328mk3L7LLr",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HelloWorld\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Calvin\"\n",
        "\n",
        "\n",
        "print(\"Hello \" + name) # --> \"Hello Calvin#"
      ],
      "metadata": {
        "id": "2JP1Ccwt7N95",
        "outputId": "c1e6f4e6-b605-4708-d423-c36dfb21d4e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2JP1Ccwt7N95",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Calvin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) Analyze the article using the Responses API\n",
        "\n",
        "### First, lets read in the article text. You don't need to understand how this works, but exposed so you can see the article text is stored in a variable called `article_text`\n"
      ],
      "metadata": {
        "id": "2K4uxTjj7STP"
      },
      "id": "2K4uxTjj7STP"
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://raw.githubusercontent.com/calisley/dpi-681/refs/heads/main/section-2/article.txt\"\n",
        "res = requests.get(URL, timeout=30)\n",
        "res.raise_for_status()\n",
        "res.encoding = res.encoding or \"utf-8\"\n",
        "article_text = res.text\n",
        "\n",
        "print(f\"Loaded from URL: {URL} ({len(article_text):,} chars)\")\n"
      ],
      "metadata": {
        "id": "oRCEdiv-8uTX",
        "outputId": "6e361e69-0163-43f2-b96d-c46c578d5bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oRCEdiv-8uTX",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded from URL: https://raw.githubusercontent.com/calisley/dpi-681/refs/heads/main/section-2/article.txt (5,964 chars)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here, use the prompt engineering tricks we discussed in class to get the model to tell you something about the article\n",
        "\n",
        "- We use that string concatenation trick here to add it to our input prompt\n",
        "\n",
        "Play around with a few different system prompts and be ready to discuss what you found."
      ],
      "metadata": {
        "id": "wJqmktE786d_"
      },
      "id": "wJqmktE786d_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a412c7c",
      "metadata": {
        "id": "7a412c7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    instructions=\"[Your system prompt here]\",\n",
        "    input=\"Analyze this article\" + article_text #String trick we learned\n",
        ")\n",
        "\n",
        "print(resp.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d96cdb",
      "metadata": {
        "id": "13d96cdb"
      },
      "source": [
        "\n",
        "## 3) Large Scale Data Analysis\n",
        "\n",
        "- For one student or quick experiments, saving to Colab's /content is fine but ephemeral.\n",
        "- For class use, create a Google Drive folder, e.g. `MyDrive/course_data/section2/`. Keep a stable path.\n",
        "- If you want students to download a canonical CSV reliably, place it in Drive and share a view-only link, or host it at a public URL (e.g., GitHub raw).\n",
        "\n",
        "Below is a helper to fetch a CSV from:\n",
        "- Drive via file ID using `gdown`, or\n",
        "- URL via `pandas.read_csv(URL)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "551c00d1",
      "metadata": {
        "id": "551c00d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example: fetch CSV from Google Drive by file ID (recommended for class distribution)\n",
        "# 1) Put CSV in Drive, right-click -> \"Get link\" -> copy the file ID from the URL.\n",
        "# 2) Paste the ID below.\n",
        "USE_GDRIVE_CSV = False\n",
        "GDRIVE_FILE_ID = \"1abcDEF_fake_id_example\"  # <-- replace with real file ID\n",
        "CSV_OUT = \"/content/my_dataset.csv\"\n",
        "\n",
        "if USE_GDRIVE_CSV:\n",
        "    import gdown, pandas as pd\n",
        "    url = f\"https://drive.google.com/uc?id={GDRIVE_FILE_ID}\"\n",
        "    gdown.download(url, CSV_OUT, quiet=False)\n",
        "    df_csv = pd.read_csv(CSV_OUT)\n",
        "    print(df_csv.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da29bea5",
      "metadata": {
        "id": "da29bea5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Alternative: load a CSV from a public URL\n",
        "USE_URL_CSV = False\n",
        "CSV_URL = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"  # example\n",
        "\n",
        "if USE_URL_CSV:\n",
        "    import pandas as pd\n",
        "    df_csv = pd.read_csv(CSV_URL)\n",
        "    print(\"Loaded CSV from URL:\", CSV_URL)\n",
        "    print(df_csv.head())\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}